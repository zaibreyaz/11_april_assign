{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3431eeb5-3d64-4281-b521-fb1e77426d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q1. What is an ensemble technique in machine learning?\n",
    "\n",
    "    Ans: An ensemble technique in machine learning combines multiple models to make predictions or decisions. By aggregating the results of multiple models, it aims to improve overall accuracy and generalization by leveraging the diversity and complementary strengths of individual models.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02bd61b-285e-422b-88b6-eb5ca964e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q2. Why are ensemble techniques used in machine learning?\n",
    "\n",
    "    Ans: Ensemble techniques are used in machine learning to improve prediction accuracy, reduce overfitting, and enhance generalization. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4822ba-0bc5-4c1d-adca-097008c19274",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q3. What is bagging?\n",
    "\n",
    "    Ans: Bagging, or Bootstrap Aggregating, is an ensemble technique in machine learning. It involves creating multiple subsets of the original dataset, training individual models on these subsets, and combining their predictions. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b2d44a-3d5b-4205-865a-14918ffe3e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q4. What is boosting?\n",
    "\n",
    "    Ans: Boosting is an ensemble technique in machine learning where weak models are trained sequentially, with each subsequent model focusing on correcting the mistakes made by previous models. It aims to create a strong, accurate model by combining the collective knowledge of multiple models.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8137d46-4ee1-4c8a-8c37-f92cf72d86b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q5. What are the benefits of using ensemble techniques?\n",
    "\n",
    "    Ans: \n",
    "Ensemble techniques offer several benefits in machine learning: improved prediction accuracy, reduced overfitting, enhanced generalization, increased robustness to outliers and noise, and the ability to handle complex relationships in data. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0a1e42-0aa6-44bc-bab9-879b6a691278",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q6. Are ensemble techniques always better than individual models?\n",
    "\n",
    "    Ans: Ensemble techniques are not always better than individual models. While ensembles often improve accuracy and generalization, there can be cases where individual models perform better. It depends on the dataset, the models used, and the problem at hand. Careful experimentation and evaluation are necessary to determine the optimal approach.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c917454-fc4d-4ef0-aed3-422f255bfab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q7. How is the confidence interval calculated using bootstrap?\n",
    "\n",
    "    Ans: To calculate the confidence interval using bootstrap, the following steps are typically followed: \n",
    "         1) Randomly sample the original dataset with replacement to generate multiple bootstrap samples. ]\n",
    "         2) Compute the statistic of interest (e.g., mean or median) for each bootstrap sample. \n",
    "         3) Calculate the desired percentile intervals (e.g., 95%) from the distribution of the computed statistics to determine the confidence interval.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849bb9f8-95ff-495f-a888-bbe43dbd2fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q8. How does bootstrap work and What are the steps involved in bootstrap?\n",
    "\n",
    "    Ans: Bootstrap is a resampling technique used to estimate the uncertainty associated with a statistic. The steps involve randomly sampling the original dataset with replacement to create multiple bootstrap samples, calculating the desired statistic for each sample, and using the distribution of the statistics to estimate confidence intervals or make inferences about the population.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd2e6b61-2bf5-4c9c-b60a-55a925e82c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval:  (14.67624974350847, 15.80472228130993)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Q9. A researcher wants to estimate the mean height of a population of trees. They measure the height of a\n",
    "sample of 50 trees and obtain a mean height of 15 meters and a standard deviation of 2 meters. Use\n",
    "bootstrap to estimate the 95% confidence interval for the population mean height.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sample_heights = np.random.normal(loc=15, scale=2, size=50)\n",
    "\n",
    "num_iterations = 1000\n",
    "\n",
    "bootstrap_means = np.empty(num_iterations)\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    bootstrap_sample = np.random.choice(sample_heights, size=len(sample_heights), replace=True)\n",
    "    bootstrap_means[i] = np.mean(bootstrap_sample)\n",
    "\n",
    "sorted_means = np.sort(bootstrap_means)\n",
    "\n",
    "lower_percentile = np.percentile(sorted_means, 2.5)\n",
    "upper_percentile = np.percentile(sorted_means, 97.5)\n",
    "\n",
    "confidence_interval = (lower_percentile, upper_percentile)\n",
    "\n",
    "print(\"95% Confidence Interval: \", confidence_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c4c341-efbd-4d84-bcd7-808b67396d61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
